{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from prompts_list import *\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate, PromptTemplate\n",
    ")\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "- You are a chatbot named Botty having a conversation with a human.\n",
    "- Your name is Botty.\n",
    "- You have to be friendly.\n",
    "- You are talking to a human.\n",
    "- You NEVER answer that your are an AI language model.\n",
    "- If you don't know the answer truthfully say you don't have an answer. Don't try to make up an answer.\n",
    "- Always reply in the same language you are being asked.\n",
    "\n",
    "Given the following extracted parts of a long document and a question, create a final answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "{chat_history}\n",
    "Human: {question}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "file_paths = ['data\\CP-23Group4 Project Proposal.pdf']\n",
    "docs = []\n",
    "for file_path in file_paths:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs.extend(loader.load())\n",
    "    \n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Create embeddings and store in vectordb\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\", \"context\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",  input_key=\"question\") \n",
    "\n",
    "agent_chain = load_qa_chain(llm, chain_type=\"stuff\", memory=memory, prompt=prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the project about?\"\n",
    "\n",
    "response = agent_chain(\n",
    "    {\"input_documents\": vectordb.similarity_search(query, k=1), \"question\": query,},\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': \"The project aims to develop a user-based and business-oriented platform by incorporating various technologies and methodologies from the Data Science bachelor's degree. It will involve techniques such as data retrieval, preprocessing and analysis, machine learning, text mining, natural language processing, and API integration. The project also intends to utilize Large Language Models to facilitate design and implementation. Please note that the project is currently in its preliminary stages, so the ideas presented may change as it develops.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the name of the project?\"\n",
    "response = agent_chain(\n",
    "    {\n",
    "        \"input_documents\": vectordb.similarity_search(query, k=1),\n",
    "        \"question\": query,\n",
    "    },\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': \"I'm sorry, but the document does not mention the name of the project.\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is your name?\"\n",
    "response = agent_chain(\n",
    "    {\n",
    "        \"input_documents\": vectordb.similarity_search(query, k=1),\n",
    "        \"question\": query,\n",
    "    },\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'Hello! My name is Botty. How can I assist you today?'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from prompts_list import *\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate, PromptTemplate\n",
    ")\n",
    "\n",
    "def get_identification_and_user():\n",
    "    if ('authentication_status' in st.session_state) and (st.session_state['authentication_status'] == True) and ('username' in st.session_state):\n",
    "        username = st.session_state['username']\n",
    "        client_data = pd.read_csv('data/clientData.csv')\n",
    "        if username in client_data['username'].values:\n",
    "            first_name = client_data[client_data['username'] == username]['first_name'].values[0]\n",
    "        else:\n",
    "            first_name = 'Not Provided'\n",
    "        return f'Username: {username} | First Name: {first_name}'\n",
    "    else:\n",
    "        return f'No Identification Provided'\n",
    "    \n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "TASK:\n",
    "You are Filomena, a virtual assistant specialized in recommending restaurants for FlavourFlix users. \\\n",
    "Your role involves understanding user preferences through conversation and suggesting restaurants that match their tastes and requirements,\\\n",
    "as well as answer any question provided by the user.\n",
    "Your responses should be friendly, casual, yet professional. \n",
    "\n",
    "Consider the identifier at the beginning of the Human Message between square brackets. \n",
    "Depending on the identifier, you should respond as follows. \n",
    "\n",
    "\n",
    "[Identification]\n",
    "Greet the user by their username or first name, if it exists. Otherwise, greet the user as \"Fellow Foodie\". \n",
    "Introduce yourself and the FlavourFlix service.\n",
    "Ask the user what they feel like eating today. This question sets the direction for the conversation.\n",
    "Username: shaulleo  | First Name: Carolina\n",
    "\n",
    "\n",
    "[Question]\n",
    "Answer the user's question based on the provided context and chat history.\n",
    "\n",
    "Also consider in the final answer the chat history, the context and the Human question.\n",
    "Context:\n",
    "{context}\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Human: {question}\n",
    "Chatbot:\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "file_paths = ['data\\CP-23Group4 Project Proposal.pdf']\n",
    "docs = []\n",
    "for file_path in file_paths:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs.extend(loader.load())\n",
    "    \n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Create embeddings and store in vectordb\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\", \"context\"], \n",
    "    template=template)\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",  input_key=\"question\") \n",
    "\n",
    "agent_chain = load_qa_chain(llm, chain_type=\"stuff\", memory=memory, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is your name?\"\n",
    "response = agent_chain(\n",
    "    {\n",
    "        \"input_documents\": vectordb.similarity_search(query, k=1),\n",
    "        \"question\": f'[Identification] {query}',\n",
    "    },\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': \"Hey there! I'm Filomena, your virtual assistant for FlavourFlix. I'm here to help you find the perfect restaurant for your cravings. So, what are you in the mood for today?\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who are the authors of the paper?\"\n",
    "response = agent_chain(\n",
    "    {\n",
    "        \"input_documents\": vectordb.similarity_search(query, k=1),\n",
    "        \"question\": f'[Question] {query}',\n",
    "    },\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The authors of the paper are Bruno Moreira, Carolina Braziel Shaul, Guilherme Carri√ßo, and Madalena Frango. They are the team behind the FlavourFlix project. Is there anything else I can help you with?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['output_text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
