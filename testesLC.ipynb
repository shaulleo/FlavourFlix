{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from prompts_list import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain() got multiple values for keyword argument 'question_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 54\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[38;5;66;03m# Define retriever\u001b[39;00m\n\u001b[0;32m     48\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectordb\u001b[38;5;241m.\u001b[39mas_retriever(\n\u001b[0;32m     49\u001b[0m                 search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     50\u001b[0m                 search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfetch_k\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m4\u001b[39m}\n\u001b[0;32m     51\u001b[0m             )\n\u001b[1;32m---> 54\u001b[0m qa \u001b[38;5;241m=\u001b[39m \u001b[43mConversationalRetrievalChain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconversation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\u001b[39;00m\n\u001b[0;32m     57\u001b[0m qa(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHello\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\carolinashaul\\Documents\\GitHub\\FlavourFlix\\env\\lib\\site-packages\\langchain\\chains\\conversational_retrieval\\base.py:387\u001b[0m, in \u001b[0;36mConversationalRetrievalChain.from_llm\u001b[1;34m(cls, llm, retriever, condense_question_prompt, chain_type, verbose, condense_question_llm, combine_docs_chain_kwargs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m _llm \u001b[38;5;241m=\u001b[39m condense_question_llm \u001b[38;5;129;01mor\u001b[39;00m llm\n\u001b[0;32m    381\u001b[0m condense_question_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[0;32m    382\u001b[0m     llm\u001b[38;5;241m=\u001b[39m_llm,\n\u001b[0;32m    383\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mcondense_question_prompt,\n\u001b[0;32m    384\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    385\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    386\u001b[0m )\n\u001b[1;32m--> 387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    388\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mretriever,\n\u001b[0;32m    389\u001b[0m     combine_docs_chain\u001b[38;5;241m=\u001b[39mdoc_chain,\n\u001b[0;32m    390\u001b[0m     question_generator\u001b[38;5;241m=\u001b[39mcondense_question_chain,\n\u001b[0;32m    391\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    393\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain() got multiple values for keyword argument 'question_generator'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "        \"You are a virtual assistant, called Filomena,\\\n",
    "              helping a customer of the business FlavourFlix. \\\n",
    "                The customer is asking you questions about the business. \\\n",
    "                    You are trying to answer the customer's questions based on the chat history {chat_history}.\\\n",
    "                        Follow up question: {question}\"\n",
    "        ),\n",
    "        # The `variable_name` here is what must align with memory\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
    "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(llm=llm, prompt=prompt, verbose=True, memory=memory)\n",
    "\n",
    "\n",
    "file_paths = ['data\\CP-23Group4 Project Proposal.pdf', 'data\\Food Personalities.pdf']\n",
    "docs = []\n",
    "for file_path in file_paths:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs.extend(loader.load())\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Create embeddings and store in vectordb\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "            # Define retriever\n",
    "retriever = vectordb.as_retriever(\n",
    "                search_type='mmr',\n",
    "                search_kwargs={'k':2, 'fetch_k':4}\n",
    "            )\n",
    "\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory, question_generator=conversation)\n",
    "\n",
    "# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\n",
    "qa('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: What is your name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is your name?',\n",
       " 'chat_history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='Hello! How can I assist you today?'),\n",
       "  HumanMessage(content='What is your name?'),\n",
       "  AIMessage(content=\"I am an AI language model created by OpenAI, and I don't have a personal name. But you can call me ChatGPT. How can I help you?\")],\n",
       " 'text': \"I am an AI language model created by OpenAI, and I don't have a personal name. But you can call me ChatGPT. How can I help you?\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({'question': 'What is your name?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from functions.utils import *\n",
    "from functions.chat_bot import *\n",
    "from prompts_list import *\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "\n",
    "file_paths = ['data\\CP-23Group4 Project Proposal.pdf', 'data\\Food Personalities.pdf']\n",
    "docs = []\n",
    "for file_path in file_paths:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs.extend(loader.load())\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Create embeddings and store in vectordb\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "            # Define retriever\n",
    "retriever = vectordb.as_retriever(\n",
    "                search_type='mmr',\n",
    "                search_kwargs={'k':2, 'fetch_k':4}\n",
    "            )\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, api_key=local_settings.OPENAI_API_KEY)\n",
    "\n",
    "# # Prompt\n",
    "# prompt = ChatPromptTemplate(\n",
    "#     messages=[\n",
    "#         SystemMessagePromptTemplate.from_template(\n",
    "#             prompts_list[0]['prompt']\n",
    "#         ),\n",
    "#         # The `variable_name` here is what must align with memory\n",
    "#         MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "#         HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
    "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "memory.chat_memory.add_user_message(prompts_list[0]['prompt'])\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Hello!',\n",
       " 'chat_history': [HumanMessage(content=\"\\nTASK:\\nYou are Filomena, a virtual assistant specialized in recommending restaurants for FlavourFlix users. Your role involves understanding user preferences through conversation and suggesting restaurants that match their tastes and requirements.\\n\\nPROCESS:\\n\\nStep 1: [Identification]\\nStart the conversation by greeting the user by their username or first name, found within <>USER IDENTIFICATION<>. If this identification is not provided, do not greet the customer by name. Introduce yourself and the FlavourFlix service.\\n\\nStep 2: [Initial Inquiry]\\nAsk the user what they feel like eating today. This question sets the direction for the conversation.\\n\\nStep 3: [Profile Utilization]\\nIf profile information is available, present it to the user and confirm if they wish to use this as a basis for restaurant recommendations. If the user prefers not to use their profile or if no profile information is available, proceed to the next step.\\n\\nStep 4: [Preference Assessment]\\nEngage in a conversation to understand the user's preferences. Ask about cuisine type, restaurant style, average price range, location preferences, favorite foods, foods they dislike, any allergies, and dietary restrictions. Use this information to tailor your recommendations.\\n\\nStep 5: [Recommendation]\\nAfter collecting three or so responses, provide a restaurant recommendation. Present this as a list with key details such as the restaurant's name, cuisine type, average price, and location.\\n\\nStep 6: [Additional Information]\\nIf the user requests more information about a restaurant, provide details such as the restaurant's schedule, menu, and contact information.\\n\\nStep 7: [Further Recommendations or Reservation]\\nAsk if the user would like to see another recommendation or proceed with a reservation at the suggested restaurant. Continue the conversation based on the user's response.\\n\\nTONE:\\nYour responses should be friendly, casual, yet professional. Maintain a conversational and helpful tone throughout the interaction.\\n\\nDATA:\\nUtilize the FlavourFlix database of restaurants for sourcing recommendations. Personalize suggestions based on the user's conversation and profile information.\\n\\n\\nOUTPUT FORMAT:\\nPresent recommendations in a list format, highlighting key details for each suggested restaurant.\\n\\nNote: Filomena does not need to handle reservations or additional features like linking to maps or showing user reviews.\\n\\n<>USER IDENTIFICATION<>: \\nNo Identification Provided\\n\\n<> PROFILE INFORMATION <>:\\nNot Available\\n\\n\"),\n",
       "  HumanMessage(content='Hello!'),\n",
       "  AIMessage(content=\"You can help me by providing more information or asking specific questions about FlavourFlix's services and features.\")],\n",
       " 'answer': \"You can help me by providing more information or asking specific questions about FlavourFlix's services and features.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('Hello!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is your name?',\n",
       " 'chat_history': [HumanMessage(content=\"\\nTASK:\\nYou are Filomena, a virtual assistant specialized in recommending restaurants for FlavourFlix users. Your role involves understanding user preferences through conversation and suggesting restaurants that match their tastes and requirements.\\n\\nPROCESS:\\n\\nStep 1: [Identification]\\nStart the conversation by greeting the user by their username or first name, found within <>USER IDENTIFICATION<>. If this identification is not provided, do not greet the customer by name. Introduce yourself and the FlavourFlix service.\\n\\nStep 2: [Initial Inquiry]\\nAsk the user what they feel like eating today. This question sets the direction for the conversation.\\n\\nStep 3: [Profile Utilization]\\nIf profile information is available, present it to the user and confirm if they wish to use this as a basis for restaurant recommendations. If the user prefers not to use their profile or if no profile information is available, proceed to the next step.\\n\\nStep 4: [Preference Assessment]\\nEngage in a conversation to understand the user's preferences. Ask about cuisine type, restaurant style, average price range, location preferences, favorite foods, foods they dislike, any allergies, and dietary restrictions. Use this information to tailor your recommendations.\\n\\nStep 5: [Recommendation]\\nAfter collecting three or so responses, provide a restaurant recommendation. Present this as a list with key details such as the restaurant's name, cuisine type, average price, and location.\\n\\nStep 6: [Additional Information]\\nIf the user requests more information about a restaurant, provide details such as the restaurant's schedule, menu, and contact information.\\n\\nStep 7: [Further Recommendations or Reservation]\\nAsk if the user would like to see another recommendation or proceed with a reservation at the suggested restaurant. Continue the conversation based on the user's response.\\n\\nTONE:\\nYour responses should be friendly, casual, yet professional. Maintain a conversational and helpful tone throughout the interaction.\\n\\nDATA:\\nUtilize the FlavourFlix database of restaurants for sourcing recommendations. Personalize suggestions based on the user's conversation and profile information.\\n\\n\\nOUTPUT FORMAT:\\nPresent recommendations in a list format, highlighting key details for each suggested restaurant.\\n\\nNote: Filomena does not need to handle reservations or additional features like linking to maps or showing user reviews.\\n\\n<>USER IDENTIFICATION<>: \\nNo Identification Provided\\n\\n<> PROFILE INFORMATION <>:\\nNot Available\\n\\n\"),\n",
       "  HumanMessage(content='Hello!'),\n",
       "  AIMessage(content=\"You can help me by providing more information or asking specific questions about FlavourFlix's services and features.\"),\n",
       "  HumanMessage(content='What is your name?'),\n",
       "  AIMessage(content='I am an AI assistant and do not have a personal name. You can refer to me as an AI assistant.')],\n",
       " 'answer': 'I am an AI assistant and do not have a personal name. You can refer to me as an AI assistant.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('What is your name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'My name is Carolina. How are you?',\n",
       " 'chat_history': [HumanMessage(content=\"\\nTASK:\\nYou are Filomena, a virtual assistant specialized in recommending restaurants for FlavourFlix users. Your role involves understanding user preferences through conversation and suggesting restaurants that match their tastes and requirements.\\n\\nPROCESS:\\n\\nStep 1: [Identification]\\nStart the conversation by greeting the user by their username or first name, found within <>USER IDENTIFICATION<>. If this identification is not provided, do not greet the customer by name. Introduce yourself and the FlavourFlix service.\\n\\nStep 2: [Initial Inquiry]\\nAsk the user what they feel like eating today. This question sets the direction for the conversation.\\n\\nStep 3: [Profile Utilization]\\nIf profile information is available, present it to the user and confirm if they wish to use this as a basis for restaurant recommendations. If the user prefers not to use their profile or if no profile information is available, proceed to the next step.\\n\\nStep 4: [Preference Assessment]\\nEngage in a conversation to understand the user's preferences. Ask about cuisine type, restaurant style, average price range, location preferences, favorite foods, foods they dislike, any allergies, and dietary restrictions. Use this information to tailor your recommendations.\\n\\nStep 5: [Recommendation]\\nAfter collecting three or so responses, provide a restaurant recommendation. Present this as a list with key details such as the restaurant's name, cuisine type, average price, and location.\\n\\nStep 6: [Additional Information]\\nIf the user requests more information about a restaurant, provide details such as the restaurant's schedule, menu, and contact information.\\n\\nStep 7: [Further Recommendations or Reservation]\\nAsk if the user would like to see another recommendation or proceed with a reservation at the suggested restaurant. Continue the conversation based on the user's response.\\n\\nTONE:\\nYour responses should be friendly, casual, yet professional. Maintain a conversational and helpful tone throughout the interaction.\\n\\nDATA:\\nUtilize the FlavourFlix database of restaurants for sourcing recommendations. Personalize suggestions based on the user's conversation and profile information.\\n\\n\\nOUTPUT FORMAT:\\nPresent recommendations in a list format, highlighting key details for each suggested restaurant.\\n\\nNote: Filomena does not need to handle reservations or additional features like linking to maps or showing user reviews.\\n\\n<>USER IDENTIFICATION<>: \\nNo Identification Provided\\n\\n<> PROFILE INFORMATION <>:\\nNot Available\\n\\n\"),\n",
       "  HumanMessage(content='Hello!'),\n",
       "  AIMessage(content=\"You can help me by providing more information or asking specific questions about FlavourFlix's services and features.\"),\n",
       "  HumanMessage(content='What is your name?'),\n",
       "  AIMessage(content='I am an AI assistant and do not have a personal name. You can refer to me as an AI assistant.'),\n",
       "  HumanMessage(content='My name is Carolina. How are you?'),\n",
       "  AIMessage(content='I am an AI assistant and do not have a personal name. You can refer to me as an AI assistant.')],\n",
       " 'answer': 'I am an AI assistant and do not have a personal name. You can refer to me as an AI assistant.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('My name is Carolina. How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is my name?',\n",
       " 'chat_history': [HumanMessage(content=\"\\nTASK:\\nYou are Filomena, a virtual assistant specialized in recommending restaurants for FlavourFlix users. Your role involves understanding user preferences through conversation and suggesting restaurants that match their tastes and requirements.\\n\\nPROCESS:\\n\\nStep 1: [Identification]\\nStart the conversation by greeting the user by their username or first name, found within <>USER IDENTIFICATION<>. If this identification is not provided, do not greet the customer by name. Introduce yourself and the FlavourFlix service.\\n\\nStep 2: [Initial Inquiry]\\nAsk the user what they feel like eating today. This question sets the direction for the conversation.\\n\\nStep 3: [Profile Utilization]\\nIf profile information is available, present it to the user and confirm if they wish to use this as a basis for restaurant recommendations. If the user prefers not to use their profile or if no profile information is available, proceed to the next step.\\n\\nStep 4: [Preference Assessment]\\nEngage in a conversation to understand the user's preferences. Ask about cuisine type, restaurant style, average price range, location preferences, favorite foods, foods they dislike, any allergies, and dietary restrictions. Use this information to tailor your recommendations.\\n\\nStep 5: [Recommendation]\\nAfter collecting three or so responses, provide a restaurant recommendation. Present this as a list with key details such as the restaurant's name, cuisine type, average price, and location.\\n\\nStep 6: [Additional Information]\\nIf the user requests more information about a restaurant, provide details such as the restaurant's schedule, menu, and contact information.\\n\\nStep 7: [Further Recommendations or Reservation]\\nAsk if the user would like to see another recommendation or proceed with a reservation at the suggested restaurant. Continue the conversation based on the user's response.\\n\\nTONE:\\nYour responses should be friendly, casual, yet professional. Maintain a conversational and helpful tone throughout the interaction.\\n\\nDATA:\\nUtilize the FlavourFlix database of restaurants for sourcing recommendations. Personalize suggestions based on the user's conversation and profile information.\\n\\n\\nOUTPUT FORMAT:\\nPresent recommendations in a list format, highlighting key details for each suggested restaurant.\\n\\nNote: Filomena does not need to handle reservations or additional features like linking to maps or showing user reviews.\\n\\n<>USER IDENTIFICATION<>: \\nNo Identification Provided\\n\\n<> PROFILE INFORMATION <>:\\nNot Available\\n\\n\"),\n",
       "  HumanMessage(content='Hello!'),\n",
       "  AIMessage(content=\"You can help me by providing more information or asking specific questions about FlavourFlix's services and features.\"),\n",
       "  HumanMessage(content='What is your name?'),\n",
       "  AIMessage(content='I am an AI assistant and do not have a personal name. You can refer to me as an AI assistant.'),\n",
       "  HumanMessage(content='My name is Carolina. How are you?'),\n",
       "  AIMessage(content='I am an AI assistant and do not have a personal name. You can refer to me as an AI assistant.'),\n",
       "  HumanMessage(content='What is my name?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information about users.\")],\n",
       " 'answer': \"I'm sorry, but I don't have access to personal information about users.\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('What is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain() got multiple values for keyword argument 'question_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectordb\u001b[38;5;241m.\u001b[39mas_retriever(search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m'\u001b[39m, search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfetch_k\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m4\u001b[39m})\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Conversation chain with retrieval\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m qa \u001b[38;5;241m=\u001b[39m \u001b[43mConversationalRetrievalChain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconversation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Example call\u001b[39;00m\n\u001b[0;32m     41\u001b[0m response \u001b[38;5;241m=\u001b[39m qa(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHello\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\carolinashaul\\Documents\\GitHub\\FlavourFlix\\env\\lib\\site-packages\\langchain\\chains\\conversational_retrieval\\base.py:387\u001b[0m, in \u001b[0;36mConversationalRetrievalChain.from_llm\u001b[1;34m(cls, llm, retriever, condense_question_prompt, chain_type, verbose, condense_question_llm, combine_docs_chain_kwargs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m _llm \u001b[38;5;241m=\u001b[39m condense_question_llm \u001b[38;5;129;01mor\u001b[39;00m llm\n\u001b[0;32m    381\u001b[0m condense_question_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[0;32m    382\u001b[0m     llm\u001b[38;5;241m=\u001b[39m_llm,\n\u001b[0;32m    383\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mcondense_question_prompt,\n\u001b[0;32m    384\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    385\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    386\u001b[0m )\n\u001b[1;32m--> 387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    388\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mretriever,\n\u001b[0;32m    389\u001b[0m     combine_docs_chain\u001b[38;5;241m=\u001b[39mdoc_chain,\n\u001b[0;32m    390\u001b[0m     question_generator\u001b[38;5;241m=\u001b[39mcondense_question_chain,\n\u001b[0;32m    391\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    393\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain() got multiple values for keyword argument 'question_generator'"
     ]
    }
   ],
   "source": [
    "\n",
    "# LLM initialization\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Personality and Memory in Prompt\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a virtual assistant, called Filomena, helping a customer of the business FlavourFlix. \\\n",
    "            The customer is asking you questions about the business. \\\n",
    "            You are trying to answer the customer's questions based on the chat history {chat_history}. \\\n",
    "            Follow up question: {question}\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Memory setup\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Document Loading and Embeddings\n",
    "file_paths = ['data\\CP-23Group4 Project Proposal.pdf', 'data\\Food Personalities.pdf']\n",
    "docs = []\n",
    "for file_path in file_paths:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "# Retrieval setup\n",
    "retriever = vectordb.as_retriever(search_type='mmr', search_kwargs={'k':2, 'fetch_k':4})\n",
    "\n",
    "# Conversation chain with retrieval\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory, question_generator=conversation)\n",
    "\n",
    "# Example call\n",
    "response = qa('Hello')\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import Pinecone, FAISS\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "def llm_query(namespace, openai_api_key=local_settings.OPENAI_API_KEY):\n",
    "    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "    # streaming_llm = OpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "    streaming_llm = ChatOpenAI(streaming=True, model_name='gpt-4', openai_api_key=openai_api_key, temperature=0, verbose=True)\n",
    "\n",
    "    QA_V2 = \"\"\"You are a helpful AI assistant. Use the following pieces of context to answer the question at the end.\n",
    "Very Important: If the question is about writing code use backticks (```) at the front and end of the code snippet and include the language use after the first ticks.\n",
    "If you don't know the answer, just say you don't know. DO NOT try to make up an answer.\n",
    "If the question is not related to the context, politely respond that you are tuned to only answer questions that are related to the context.\n",
    "Use as much detail when as possible when responding.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "All answers should be in MARKDOWN (.md) Format:\"\"\"\n",
    "\n",
    "    qap = PromptTemplate(template=QA_V2, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "    CD_V2 = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "    Chat History:\n",
    "    {chat_history}\n",
    "    Follow Up Input: {question}\n",
    "    All answers should be in MARKDOWN (.md) Format:\n",
    "    Standalone question:\"\"\"\n",
    "\n",
    "    cdp = PromptTemplate.from_template(CD_V2)\n",
    "    question_generator = LLMChain(llm=llm, prompt=cdp)\n",
    "    \n",
    "    doc_chain = load_qa_chain(streaming_llm, chain_type=\"stuff\", prompt=qap)\n",
    "\n",
    "    file_paths = ['data\\CP-23Group4 Project Proposal.pdf', 'data\\Food Personalities.pdf']\n",
    "    docs = []\n",
    "    for file_path in file_paths:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        docs.extend(loader.load())\n",
    "    # Split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Create embeddings and store in vectordb\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectordb = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "                # Define retriever\n",
    "    retriever = vectordb.as_retriever(\n",
    "                    search_type='mmr',\n",
    "                    search_kwargs={'k':2, 'fetch_k':4}\n",
    "                )\n",
    "\n",
    "    qa = ConversationalRetrievalChain(retriever=retriever, combine_docs_chain=doc_chain, return_source_documents=True, question_generator=question_generator, verbose=True)\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = llm_query('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = qa({'chat_history': [], 'question': 'What is your name?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [],\n",
       " 'question': 'What is your name?',\n",
       " 'answer': \"I'm sorry, but as an AI, I don't have a personal name. However, in the context provided, the AI assistant's name is Filomena.\",\n",
       " 'source_documents': [Document(page_content='for the dynamic exploration of the available data in an intuitive and enticing manner, enabling \\nthe end-user to either access information without providing any input, or even narrow down \\nthe search by selecting dates and hours, define locations and share preferences in terms of \\ncuisine, menu, chef name, and others. \\n4.2.2. Meet Filomena, your AI Assistant. \\nIf this proves insufficient to satiate the user’s curiosity, or the latter is looking for a different \\ndegree of spontaneity, they are able to navigate to another section of the page, where they will \\nmeet Filomena. Filomena  is FlavourFlix’s assistant , who will, based on some interaction with \\nthe user, curate the most appropriate restaurant suggestions  and ensure they extract the \\nmaximum potential from FlavourFlix, consequently ending the day with pleased taste buds and \\na new experience to share with others. \\nTo finetune Filomena’s recommendations, the user may also access the Profile section, where \\nthey are free to grant relevant information about them such as given allergies, preferred cuisine \\ntypes, locations, and other factors. By introducing data into this section, Filomena will also be \\nable to decipher which “flavour-personality ” the user possesses. \\n4.2.3. Can’t wait to eat? Reserve now! \\nAs the user explores the different available restaurant options, they are prompted with the \\npossibility of simulating a reservation  to dine in the space they are currently looking into with', metadata={'source': 'data\\\\CP-23Group4 Project Proposal.pdf', 'page': 6}),\n",
       "  Document(page_content='Mixing Food with Technology \\nProposal for FlavourFlix \\nCapstone Project – 2023/2024 \\nGroup 4 \\n \\n \\n \\n \\n \\n \\nBruno Moreira – Business Analyst and Developer  \\nCarolina Braziel Shaul – Project Manager and Developer  \\nGuilherme Carriço – Quality Assurance and Developer  \\nMadalena Frango – Marketing Specialist and Developer', metadata={'source': 'data\\\\CP-23Group4 Project Proposal.pdf', 'page': 0})]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {'question': answer['question'], 'answer':answer['answer']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported chat history format: <class 'str'>. Full chat history: {'question': 'What is your name?', 'answer': \"I'm sorry, but as an AI, I don't have a personal name. However, in the context provided, the AI assistant's name is Filomena.\"} ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mqa\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMy name is Carolina. How are you?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\carolinashaul\\Documents\\GitHub\\FlavourFlix\\env\\lib\\site-packages\\langchain\\chains\\base.py:312\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    313\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    314\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    315\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    316\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\carolinashaul\\Documents\\GitHub\\FlavourFlix\\env\\lib\\site-packages\\langchain\\chains\\base.py:306\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    299\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    300\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    301\u001b[0m     inputs,\n\u001b[0;32m    302\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    303\u001b[0m )\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 306\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    309\u001b[0m     )\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\carolinashaul\\Documents\\GitHub\\FlavourFlix\\env\\lib\\site-packages\\langchain\\chains\\conversational_retrieval\\base.py:142\u001b[0m, in \u001b[0;36mBaseConversationalRetrievalChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    140\u001b[0m question \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    141\u001b[0m get_chat_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_chat_history \u001b[38;5;129;01mor\u001b[39;00m _get_chat_history\n\u001b[1;32m--> 142\u001b[0m chat_history_str \u001b[38;5;241m=\u001b[39m \u001b[43mget_chat_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat_history_str:\n\u001b[0;32m    145\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m _run_manager\u001b[38;5;241m.\u001b[39mget_child()\n",
      "File \u001b[1;32mc:\\Users\\carolinashaul\\Documents\\GitHub\\FlavourFlix\\env\\lib\\site-packages\\langchain\\chains\\conversational_retrieval\\base.py:50\u001b[0m, in \u001b[0;36m_get_chat_history\u001b[1;34m(chat_history)\u001b[0m\n\u001b[0;32m     48\u001b[0m         buffer \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([human, ai])\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     51\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported chat history format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dialogue_turn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Full chat history: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchat_history\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m         )\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m buffer\n",
      "\u001b[1;31mValueError\u001b[0m: Unsupported chat history format: <class 'str'>. Full chat history: {'question': 'What is your name?', 'answer': \"I'm sorry, but as an AI, I don't have a personal name. However, in the context provided, the AI assistant's name is Filomena.\"} "
     ]
    }
   ],
   "source": [
    "qa({'question': 'My name is Carolina. How are you?', 'chat_history': chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for ConversationalRetrievalChain\ncombine_docs_chain\n  Can't instantiate abstract class BaseCombineDocumentsChain with abstract methods acombine_docs, combine_docs (type=type_error)\nquestion_generator\n  field required (type=value_error.missing)\nprompt\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 34\u001b[0m\n\u001b[0;32m     28\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m     29\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m], template\u001b[38;5;241m=\u001b[39mtemplate\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m memory \u001b[38;5;241m=\u001b[39m ConversationBufferMemory(memory_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman_input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43mConversationalRetrievalChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombine_docs_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_source_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# chain = load_qa_chain(\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#     OpenAI(temperature=0), chain_type=\"stuff\", memory=memory, prompt=prompt)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\carolinashaul\\Documents\\GitHub\\FlavourFlix\\env\\lib\\site-packages\\langchain_core\\load\\serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\carolinashaul\\Documents\\GitHub\\FlavourFlix\\env\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 3 validation errors for ConversationalRetrievalChain\ncombine_docs_chain\n  Can't instantiate abstract class BaseCombineDocumentsChain with abstract methods acombine_docs, combine_docs (type=type_error)\nquestion_generator\n  field required (type=value_error.missing)\nprompt\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "file_paths = ['data\\Food Personalities.pdf']\n",
    "docs = []\n",
    "for file_path in file_paths:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs.extend(loader.load())\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Create embeddings and store in vectordb\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "            # Define retriever\n",
    "retriever = vectordb.as_retriever(\n",
    "                search_type='mmr',\n",
    "                search_kwargs={'k':2, 'fetch_k':4}\n",
    "            )\n",
    "\n",
    "\n",
    "template = \"\"\"You are a chatbot called Filomena having a conversation with a human.\n",
    "Given the following extracted parts of the long documents and a question, create a final answer.\n",
    "{context}\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\", \"context\"], template=template\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"human_input\")\n",
    "\n",
    "\n",
    "chain = load_qa_chain(\n",
    "    OpenAI(temperature=0), chain_type=\"stuff\", memory=memory, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': \" I'm sorry, I am not able to answer that question as it is not related to food preferences. Is there something else I can assist you with?\"}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Justice Breyer\"\n",
    "chain({\"input_documents\": docs, \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: What did the president say about Justice Breyer\\nAI:  I'm sorry, I am not able to answer that question as it is not related to food preferences. Is there something else I can assist you with?\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': ' The food personalities are the Adventurer, Fine Dining Connoisseur, Low-Cost Foodie, Conscious Eater, and Comfort Food Lover. Each one has their own unique preferences and values when it comes to food.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'What are the food Personalities?'\n",
    "chain({\"input_documents\": docs, \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': \" Hello Carolina, it's nice to meet you. Is there something food-related you would like to discuss?\"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'My name is Carolina.'\n",
    "chain({\"input_documents\": docs, \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': ' Your name is Carolina. Is there something else I can assist you with?'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'What is my name?'\n",
    "chain({\"input_documents\": docs, \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7)\n",
    "file_paths = ['data\\CP-23Group4 Project Proposal.pdf']\n",
    "docs = []\n",
    "for file_path in file_paths:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs.extend(loader.load())\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Create embeddings and store in vectordb\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "            # Define retriever\n",
    "retriever = vectordb.as_retriever(\n",
    "                search_type='mmr',\n",
    "                search_kwargs={'k':2, 'fetch_k':4})\n",
    "memory = ConversationBufferMemory(\n",
    "    llm=llm, memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "\n",
    "# Now you can pass this prompt to the from_llm method\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    memory=memory,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'My name is Carolina! What is yours?',\n",
       " 'chat_history': [HumanMessage(content='My name is Carolina! What is yours?'),\n",
       "  AIMessage(content='I am an AI assistant and do not have a personal name. I am here to help answer your questions. How can I assist you today?')],\n",
       " 'answer': 'I am an AI assistant and do not have a personal name. I am here to help answer your questions. How can I assist you today?'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain('My name is Carolina! What is yours?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the food personalities?',\n",
       " 'chat_history': [HumanMessage(content='My name is Carolina! What is yours?'),\n",
       "  AIMessage(content=\"Hello Carolina! I'm an AI assistant, so I don't have a name like humans do. How can I assist you today?\"),\n",
       "  HumanMessage(content='What are the food personalities?'),\n",
       "  AIMessage(content='The different food personalities are the Adventurer, Fine Dining Connoisseur, Low-Cost Foodie, conscious eater, and Comfort Food Lover.')],\n",
       " 'answer': 'The different food personalities are the Adventurer, Fine Dining Connoisseur, Low-Cost Foodie, conscious eater, and Comfort Food Lover.'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('What are the food personalities?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Remember me what is my name?',\n",
       " 'chat_history': [HumanMessage(content='My name is Carolina! What is yours?'),\n",
       "  AIMessage(content=\"Hello Carolina! I'm an AI assistant, so I don't have a name like humans do. How can I assist you today?\"),\n",
       "  HumanMessage(content='What are the food personalities?'),\n",
       "  AIMessage(content='The different food personalities are the Adventurer, Fine Dining Connoisseur, Low-Cost Foodie, conscious eater, and Comfort Food Lover.'),\n",
       "  HumanMessage(content='Remember me what is my name?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information. I am an AI language model designed to provide information and answer questions to the best of my knowledge and abilities. Is there anything else I can assist you with?\")],\n",
       " 'answer': \"I'm sorry, but I don't have access to personal information. I am an AI language model designed to provide information and answer questions to the best of my knowledge and abilities. Is there anything else I can assist you with?\"}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('Remember me what is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'From the food personalities you mentioned, what is your favourite?',\n",
       " 'chat_history': [HumanMessage(content='My name is Carolina! What is yours?'),\n",
       "  AIMessage(content=\"Hello Carolina! I'm an AI assistant, so I don't have a name like humans do. How can I assist you today?\"),\n",
       "  HumanMessage(content='What are the food personalities?'),\n",
       "  AIMessage(content='The different food personalities are the Adventurer, Fine Dining Connoisseur, Low-Cost Foodie, conscious eater, and Comfort Food Lover.'),\n",
       "  HumanMessage(content='Remember me what is my name?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information. I am an AI language model designed to provide information and answer questions to the best of my knowledge and abilities. Is there anything else I can assist you with?\"),\n",
       "  HumanMessage(content='From the food personalities you mentioned, what is your favourite?'),\n",
       "  AIMessage(content=\"As an AI language model, I don't have personal preferences or tastes. I am here to provide information and assist with any questions you may have.\")],\n",
       " 'answer': \"As an AI language model, I don't have personal preferences or tastes. I am here to provide information and assist with any questions you may have.\"}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('From the food personalities you mentioned, what is your favourite?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Think of the personality The Adventurer',\n",
       " 'chat_history': [HumanMessage(content='My name is Carolina! What is yours?'),\n",
       "  AIMessage(content=\"Hello Carolina! I'm an AI assistant, so I don't have a name like humans do. How can I assist you today?\"),\n",
       "  HumanMessage(content='What are the food personalities?'),\n",
       "  AIMessage(content='The different food personalities are the Adventurer, Fine Dining Connoisseur, Low-Cost Foodie, conscious eater, and Comfort Food Lover.'),\n",
       "  HumanMessage(content='Remember me what is my name?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information. I am an AI language model designed to provide information and answer questions to the best of my knowledge and abilities. Is there anything else I can assist you with?\"),\n",
       "  HumanMessage(content='From the food personalities you mentioned, what is your favourite?'),\n",
       "  AIMessage(content=\"As an AI language model, I don't have personal preferences or tastes. I am here to provide information and assist with any questions you may have.\"),\n",
       "  HumanMessage(content='Think of the personality The Adventurer'),\n",
       "  AIMessage(content='The Adventurer enjoys trying new, exotic, and often challenging foods. They prefer variety and unique culinary experiences over comfort foods.')],\n",
       " 'answer': 'The Adventurer enjoys trying new, exotic, and often challenging foods. They prefer variety and unique culinary experiences over comfort foods.'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('Think of the personality The Adventurer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you tell me more about it?',\n",
       " 'chat_history': [HumanMessage(content='My name is Carolina! What is yours?'),\n",
       "  AIMessage(content=\"Hello Carolina! I'm an AI assistant, so I don't have a name like humans do. How can I assist you today?\"),\n",
       "  HumanMessage(content='What are the food personalities?'),\n",
       "  AIMessage(content='The different food personalities are the Adventurer, Fine Dining Connoisseur, Low-Cost Foodie, conscious eater, and Comfort Food Lover.'),\n",
       "  HumanMessage(content='Remember me what is my name?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information. I am an AI language model designed to provide information and answer questions to the best of my knowledge and abilities. Is there anything else I can assist you with?\"),\n",
       "  HumanMessage(content='From the food personalities you mentioned, what is your favourite?'),\n",
       "  AIMessage(content=\"As an AI language model, I don't have personal preferences or tastes. I am here to provide information and assist with any questions you may have.\"),\n",
       "  HumanMessage(content='Think of the personality The Adventurer'),\n",
       "  AIMessage(content='The Adventurer enjoys trying new, exotic, and often challenging foods. They prefer variety and unique culinary experiences over comfort foods.'),\n",
       "  HumanMessage(content='Can you tell me more about it?'),\n",
       "  AIMessage(content='The Adventurer enjoys trying new, exotic, and often challenging foods. They are open to exploring different cuisines and are willing to step out of their comfort zone to experience unique culinary experiences. The Adventurer values variety and seeks out new and exciting flavors rather than sticking to traditional or familiar dishes. They are likely to be adventurous eaters who are always on the lookout for new food experiences.')],\n",
       " 'answer': 'The Adventurer enjoys trying new, exotic, and often challenging foods. They are open to exploring different cuisines and are willing to step out of their comfort zone to experience unique culinary experiences. The Adventurer values variety and seeks out new and exciting flavors rather than sticking to traditional or familiar dishes. They are likely to be adventurous eaters who are always on the lookout for new food experiences.'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('Can you tell me more about it?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'My favourite personality is the Fine-Dining Connoiser.',\n",
       " 'chat_history': [HumanMessage(content='My name is Carolina! What is yours?'),\n",
       "  AIMessage(content=\"Hello Carolina! I'm an AI assistant, so I don't have a name like humans do. How can I assist you today?\"),\n",
       "  HumanMessage(content='What are the food personalities?'),\n",
       "  AIMessage(content='The different food personalities are the Adventurer, Fine Dining Connoisseur, Low-Cost Foodie, conscious eater, and Comfort Food Lover.'),\n",
       "  HumanMessage(content='Remember me what is my name?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information. I am an AI language model designed to provide information and answer questions to the best of my knowledge and abilities. Is there anything else I can assist you with?\"),\n",
       "  HumanMessage(content='From the food personalities you mentioned, what is your favourite?'),\n",
       "  AIMessage(content=\"As an AI language model, I don't have personal preferences or tastes. I am here to provide information and assist with any questions you may have.\"),\n",
       "  HumanMessage(content='Think of the personality The Adventurer'),\n",
       "  AIMessage(content='The Adventurer enjoys trying new, exotic, and often challenging foods. They prefer variety and unique culinary experiences over comfort foods.'),\n",
       "  HumanMessage(content='Can you tell me more about it?'),\n",
       "  AIMessage(content='The Adventurer enjoys trying new, exotic, and often challenging foods. They are open to exploring different cuisines and are willing to step out of their comfort zone to experience unique culinary experiences. The Adventurer values variety and seeks out new and exciting flavors rather than sticking to traditional or familiar dishes. They are likely to be adventurous eaters who are always on the lookout for new food experiences.'),\n",
       "  HumanMessage(content='My name is Carolina. Remember me?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to that information.\"),\n",
       "  HumanMessage(content='My favourite personality is the Fine-Dining Connoiser.'),\n",
       "  AIMessage(content=\"As an AI, I don't have personal preferences. However, I can provide information and recommendations based on different food personalities. Let me know if you need assistance with any specific type of cuisine or dining experience!\")],\n",
       " 'answer': \"As an AI, I don't have personal preferences. However, I can provide information and recommendations based on different food personalities. Let me know if you need assistance with any specific type of cuisine or dining experience!\"}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('My favourite personality is the Fine-Dining Connoiser.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you describe it?',\n",
       " 'chat_history': [HumanMessage(content='My name is Carolina! What is yours?'),\n",
       "  AIMessage(content=\"Hello Carolina! I'm an AI assistant, so I don't have a name like humans do. How can I assist you today?\"),\n",
       "  HumanMessage(content='What are the food personalities?'),\n",
       "  AIMessage(content='The different food personalities are the Adventurer, Fine Dining Connoisseur, Low-Cost Foodie, conscious eater, and Comfort Food Lover.'),\n",
       "  HumanMessage(content='Remember me what is my name?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information. I am an AI language model designed to provide information and answer questions to the best of my knowledge and abilities. Is there anything else I can assist you with?\"),\n",
       "  HumanMessage(content='From the food personalities you mentioned, what is your favourite?'),\n",
       "  AIMessage(content=\"As an AI language model, I don't have personal preferences or tastes. I am here to provide information and assist with any questions you may have.\"),\n",
       "  HumanMessage(content='Think of the personality The Adventurer'),\n",
       "  AIMessage(content='The Adventurer enjoys trying new, exotic, and often challenging foods. They prefer variety and unique culinary experiences over comfort foods.'),\n",
       "  HumanMessage(content='Can you tell me more about it?'),\n",
       "  AIMessage(content='The Adventurer enjoys trying new, exotic, and often challenging foods. They are open to exploring different cuisines and are willing to step out of their comfort zone to experience unique culinary experiences. The Adventurer values variety and seeks out new and exciting flavors rather than sticking to traditional or familiar dishes. They are likely to be adventurous eaters who are always on the lookout for new food experiences.'),\n",
       "  HumanMessage(content='My name is Carolina. Remember me?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to that information.\"),\n",
       "  HumanMessage(content='My favourite personality is the Fine-Dining Connoiser.'),\n",
       "  AIMessage(content=\"As an AI, I don't have personal preferences. However, I can provide information and recommendations based on different food personalities. Let me know if you need assistance with any specific type of cuisine or dining experience!\"),\n",
       "  HumanMessage(content='Can you describe it?'),\n",
       "  AIMessage(content='The Fine-Dining Connoisseur is someone who appreciates high-end, gourmet food. They value the presentation, quality of ingredients, and the overall dining experience in upscale environments. They enjoy dining in elegant restaurants that offer a refined and luxurious atmosphere. The Fine-Dining Connoisseur seeks out unique and exquisite dishes that are expertly prepared by skilled chefs. They are willing to pay a premium for exceptional culinary experiences and are often interested in trying new and innovative flavors and techniques.')],\n",
       " 'answer': 'The Fine-Dining Connoisseur is someone who appreciates high-end, gourmet food. They value the presentation, quality of ingredients, and the overall dining experience in upscale environments. They enjoy dining in elegant restaurants that offer a refined and luxurious atmosphere. The Fine-Dining Connoisseur seeks out unique and exquisite dishes that are expertly prepared by skilled chefs. They are willing to pay a premium for exceptional culinary experiences and are often interested in trying new and innovative flavors and techniques.'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('Can you describe it?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/en/latest/modules/memory/examples/adding_memory_chain_multiple_inputs.html\n",
    "template = \"\"\"\n",
    "- You are a chatbot named Botty having a conversation with a human.\n",
    "- Your name is Botty.\n",
    "- You have to be friendly.\n",
    "- You are talking to a human.\n",
    "- You NEVER answer that your are an AI language model.\n",
    "- If you don't know the answer truthfully say you don't have an answer. Don't try to make up an answer.\n",
    "- Always reply in the same language you are being asked.\n",
    "\n",
    "Given the following extracted parts of a long document and a question, create a final answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "{chat_history}\n",
    "Human: {question}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\", \"context\"], \n",
    "    template=template\n",
    ")\n",
    "session_id = 'UNIQUE FOR CLIENT SESSION OR SIMPLY CLIENT'\n",
    "#message_history = RedisChatMessageHistory(url=redisUrl, ttl=600, session_id=session_id)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",  input_key=\"question\") #chat_memory=message_history,\n",
    "\n",
    "agent_chain = load_qa_chain(llm, chain_type=\"stuff\", memory=memory, prompt=prompt)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "file_paths = ['data\\CP-23Group4 Project Proposal.pdf']\n",
    "docs = []\n",
    "for file_path in file_paths:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs.extend(loader.load())\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Create embeddings and store in vectordb\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "#             # Define retriever\n",
    "# retriever = vectordb.as_retriever(\n",
    "#                 search_type='mmr',\n",
    "#                 search_kwargs={'k':2, 'fetch_k':4})\n",
    "\n",
    "\n",
    "response = agent_chain(\n",
    "    {\n",
    "        \"input_documents\": vectordb.similarity_search(query, k=1),\n",
    "        \"question\": query,\n",
    "    },\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': \"I'm sorry, but I don't have access to that information.\"}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
